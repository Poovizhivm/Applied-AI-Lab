{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcbd0e5-60c6-482c-858e-3e5e343c0455",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from IPython.display import HTML\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67747436-57ac-4435-b074-ebbe0e36c988",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592de400-c050-4144-abd1-5e3e17c42bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(X):\n",
    "    f1 = np.mean(X, axis=(1,2))\n",
    "    f2 = np.std(X, axis=(1,2))\n",
    "    return np.column_stack((f1, f2))\n",
    "X_train_feat = extract_features(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bf0149-516b-4c92-a9ca-5de145069d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(X_train_feat, axis=0)\n",
    "std = np.std(X_train_feat, axis=0)\n",
    "X_train_feat = (X_train_feat - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b9608f-2604-4267-bf09-1c872c1488ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(y, num_classes=10):\n",
    "    return np.eye(num_classes)[y]\n",
    "y_train_oh = one_hot(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214d5a94-130b-45ce-b70f-6ad2dc68e2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    z = z - np.max(z, axis=1, keepdims=True)\n",
    "    exp_z = np.exp(z)\n",
    "    return exp_z / np.sum(exp_z, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65f84ec-7556-4efd-bcc4-63c5f0f3b105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(X, y, W):\n",
    "    logits = X @ W\n",
    "    probs = softmax(logits)\n",
    "    return -np.sum(y * np.log(probs + 1e-8)) / X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4079eb14-8a4a-473e-8507-3554837bd30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(X, y, W):\n",
    "    logits = X @ W\n",
    "    probs = softmax(logits)\n",
    "    return (X.T @ (probs - y)) / X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3e19e4-24c5-41be-9c4d-2af0d8e8228b",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "iterations = 100\n",
    "initial_W = np.zeros((2,10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddeb7bf9-06fd-474a-800c-242f6d70dd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y):\n",
    "    W = initial_W.copy()\n",
    "    history = []\n",
    "    for i in range(iterations):\n",
    "        loss = compute_loss(X, y, W)\n",
    "        history.append((W.copy(), loss))\n",
    "        grad = compute_gradient(X, y, W)\n",
    "        W -= learning_rate * grad\n",
    "    return W, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b7c596-5fda-4959-8db8-7febf6d713cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(X, y):\n",
    "    W = initial_W.copy()\n",
    "    history = []\n",
    "    n = len(y)\n",
    "    for i in range(iterations):\n",
    "        loss = compute_loss(X, y, W)\n",
    "        history.append((W.copy(), loss))\n",
    "        idx = np.random.randint(0, n)\n",
    "        grad = compute_gradient(X[idx:idx+1], y[idx:idx+1], W)\n",
    "        W -= learning_rate * grad\n",
    "    return W, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91baef2-7aa3-46e2-80b7-6bed2b382b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_batch(X, y, batch_size=64):\n",
    "    W = initial_W.copy()\n",
    "    history = []\n",
    "    n = len(y)\n",
    "    for i in range(iterations):\n",
    "        loss = compute_loss(X, y, W)\n",
    "        history.append((W.copy(), loss))\n",
    "        idx = np.random.choice(n, batch_size, replace=False)\n",
    "        grad = compute_gradient(X[idx], y[idx], W)\n",
    "        W -= learning_rate * grad\n",
    "    return W, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1df3a60-da02-45f6-a467-612172128846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nesterov(X, y, momentum=0.9):\n",
    "    W = initial_W.copy()\n",
    "    V = np.zeros_like(W)\n",
    "    history = []\n",
    "    for i in range(iterations):\n",
    "        loss = compute_loss(X, y, W)\n",
    "        history.append((W.copy(), loss))\n",
    "        lookahead = W - momentum * V\n",
    "        grad = compute_gradient(X, y, lookahead)\n",
    "        V = momentum * V + learning_rate * grad\n",
    "        W -= V\n",
    "    return W, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06b68a1-5926-48e3-a3a4-9e82c3543abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adagrad(X, y):\n",
    "    W = initial_W.copy()\n",
    "    G = np.zeros_like(W)\n",
    "    history = []\n",
    "    eps = 1e-8\n",
    "    for i in range(iterations):\n",
    "        loss = compute_loss(X, y, W)\n",
    "        history.append((W.copy(), loss))\n",
    "        grad = compute_gradient(X, y, W)\n",
    "        G += grad**2\n",
    "        W -= learning_rate * grad / (np.sqrt(G) + eps)\n",
    "    return W, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d9c9e7-8163-40c4-ace7-32fce0a794f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsprop(X, y, beta=0.9):\n",
    "    W = initial_W.copy()\n",
    "    E = np.zeros_like(W)\n",
    "    history = []\n",
    "    eps = 1e-8\n",
    "    for i in range(iterations):\n",
    "        loss = compute_loss(X, y, W)\n",
    "        history.append((W.copy(), loss))\n",
    "        grad = compute_gradient(X, y, W)\n",
    "        E = beta * E + (1-beta) * grad**2\n",
    "        W -= learning_rate * grad / (np.sqrt(E) + eps)\n",
    "    return W, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e698e842-85df-410c-8b1d-24d5fbc847c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adam(X, y):\n",
    "    W = initial_W.copy()\n",
    "    m = np.zeros_like(W)\n",
    "    v = np.zeros_like(W)\n",
    "    history = []\n",
    "    beta1, beta2 = 0.9, 0.999\n",
    "    eps = 1e-8\n",
    "    for t in range(1, iterations+1):\n",
    "        loss = compute_loss(X, y, W)\n",
    "        history.append((W.copy(), loss))\n",
    "        grad = compute_gradient(X, y, W)\n",
    "        m = beta1*m + (1-beta1)*grad\n",
    "        v = beta2*v + (1-beta2)*(grad**2)\n",
    "        m_hat = m/(1-beta1**t)\n",
    "        v_hat = v/(1-beta2**t)\n",
    "        W -= learning_rate * m_hat/(np.sqrt(v_hat)+eps)\n",
    "    return W, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad621001-7e86-4d23-b0ec-a74a70ccf5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_gd, hist_gd = gradient_descent(X_train_feat, y_train_oh)\n",
    "W_sgd, hist_sgd = sgd(X_train_feat, y_train_oh)\n",
    "W_mb, hist_mb = mini_batch(X_train_feat, y_train_oh)\n",
    "W_nest, hist_nest = nesterov(X_train_feat, y_train_oh)\n",
    "W_ada, hist_ada = adagrad(X_train_feat, y_train_oh)\n",
    "W_rms, hist_rms = rmsprop(X_train_feat, y_train_oh)\n",
    "W_adam, hist_adam = adam(X_train_feat, y_train_oh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85ae5a8-6955-4833-85cb-05409c7b37e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "ax.set_xlim(0, iterations)\n",
    "\n",
    "max_loss = max(\n",
    "    max([h[1] for h in hist_gd]),\n",
    "    max([h[1] for h in hist_sgd]),\n",
    "    max([h[1] for h in hist_mb]),\n",
    "    max([h[1] for h in hist_nest]),\n",
    "    max([h[1] for h in hist_ada]),\n",
    "    max([h[1] for h in hist_rms]),\n",
    "    max([h[1] for h in hist_adam])\n",
    ")\n",
    "\n",
    "ax.set_ylim(0, max_loss)\n",
    "\n",
    "# Create empty lines\n",
    "gd_line,   = ax.plot([], [], label=\"GD\")\n",
    "sgd_line,  = ax.plot([], [], label=\"SGD\")\n",
    "mb_line,   = ax.plot([], [], label=\"Mini-Batch\")\n",
    "nest_line, = ax.plot([], [], label=\"Nesterov\")\n",
    "ada_line,  = ax.plot([], [], label=\"Adagrad\")\n",
    "rms_line,  = ax.plot([], [], label=\"RMSProp\")\n",
    "adam_line, = ax.plot([], [], label=\"Adam\")\n",
    "\n",
    "ax.set_xlabel(\"Iteration\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.set_title(\"Loss vs Iteration (All Optimizers)\")\n",
    "ax.legend()\n",
    "\n",
    "def update(frame):\n",
    "\n",
    "    gd_line.set_data(range(frame),   [h[1] for h in hist_gd[:frame]])\n",
    "    sgd_line.set_data(range(frame),  [h[1] for h in hist_sgd[:frame]])\n",
    "    mb_line.set_data(range(frame),   [h[1] for h in hist_mb[:frame]])\n",
    "    nest_line.set_data(range(frame), [h[1] for h in hist_nest[:frame]])\n",
    "    ada_line.set_data(range(frame),  [h[1] for h in hist_ada[:frame]])\n",
    "    rms_line.set_data(range(frame),  [h[1] for h in hist_rms[:frame]])\n",
    "    adam_line.set_data(range(frame), [h[1] for h in hist_adam[:frame]])\n",
    "\n",
    "    return (gd_line, sgd_line, mb_line,\n",
    "            nest_line, ada_line, rms_line, adam_line)\n",
    "\n",
    "ani = animation.FuncAnimation(\n",
    "    fig,\n",
    "    update,\n",
    "    frames=range(1, iterations),\n",
    "    interval=80,\n",
    "    blit=False\n",
    ")\n",
    "\n",
    "HTML(ani.to_jshtml())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1726ebca-5e49-4a92-bba6-367fd7b5ceeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1_vals = np.linspace(-5, 5, 100)\n",
    "w2_vals = np.linspace(-5, 5, 100)\n",
    "\n",
    "W1, W2 = np.meshgrid(w1_vals, w2_vals)\n",
    "Loss_surface = np.zeros_like(W1)\n",
    "\n",
    "W_base = W_adam.copy()  \n",
    "\n",
    "for i in range(W1.shape[0]):\n",
    "    for j in range(W1.shape[1]):\n",
    "        W_temp = W_base.copy()\n",
    "        W_temp[0,0] = W1[i,j]\n",
    "        W_temp[1,0] = W2[i,j]\n",
    "        Loss_surface[i,j] = compute_loss(X_train_feat, y_train_oh, W_temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b41510-e9df-4e2c-9a4c-1213fbaa9f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_gd   = np.array([h[0][0:2,0] for h in hist_gd])\n",
    "traj_sgd  = np.array([h[0][0:2,0] for h in hist_sgd])\n",
    "traj_mb   = np.array([h[0][0:2,0] for h in hist_mb])\n",
    "traj_nest = np.array([h[0][0:2,0] for h in hist_nest])\n",
    "traj_ada  = np.array([h[0][0:2,0] for h in hist_ada])\n",
    "traj_rms  = np.array([h[0][0:2,0] for h in hist_rms])\n",
    "traj_adam = np.array([h[0][0:2,0] for h in hist_adam])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0837555c-bca1-4493-aaa6-6a19f9d95532",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "ax.contour(W1, W2, Loss_surface, levels=50)\n",
    "\n",
    "lines = {}\n",
    "\n",
    "names = [\"GD\",\"SGD\",\"MB\",\"Nesterov\",\"Adagrad\",\"RMSProp\",\"Adam\"]\n",
    "colors = [\"r\",\"g\",\"b\",\"c\",\"m\",\"y\",\"k\"]\n",
    "\n",
    "for name, color in zip(names, colors):\n",
    "    lines[name], = ax.plot([], [], marker='o', linestyle='-', color=color, label=name)\n",
    "\n",
    "ax.set_xlabel(\"W[0,0]\")\n",
    "ax.set_ylabel(\"W[1,0]\")\n",
    "ax.set_title(\"2D Contour - Optimizer Trajectories\")\n",
    "ax.legend()\n",
    "\n",
    "def update2d(frame):\n",
    "    lines[\"GD\"].set_data(traj_gd[:frame,0], traj_gd[:frame,1])\n",
    "    lines[\"SGD\"].set_data(traj_sgd[:frame,0], traj_sgd[:frame,1])\n",
    "    lines[\"MB\"].set_data(traj_mb[:frame,0], traj_mb[:frame,1])\n",
    "    lines[\"Nesterov\"].set_data(traj_nest[:frame,0], traj_nest[:frame,1])\n",
    "    lines[\"Adagrad\"].set_data(traj_ada[:frame,0], traj_ada[:frame,1])\n",
    "    lines[\"RMSProp\"].set_data(traj_rms[:frame,0], traj_rms[:frame,1])\n",
    "    lines[\"Adam\"].set_data(traj_adam[:frame,0], traj_adam[:frame,1])\n",
    "    return list(lines.values())\n",
    "\n",
    "ani2d = animation.FuncAnimation(\n",
    "    fig,\n",
    "    update2d,\n",
    "    frames=iterations,\n",
    "    interval=80\n",
    ")\n",
    "\n",
    "HTML(ani2d.to_jshtml())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04290170-93b8-48e1-bfed-c146568f96f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3d = plt.figure(figsize=(10,7))\n",
    "ax3d = fig3d.add_subplot(111, projection='3d')\n",
    "\n",
    "ax3d.plot_surface(W1, W2, Loss_surface, cmap='viridis', alpha=0.6)\n",
    "\n",
    "points = {}\n",
    "\n",
    "for name, color in zip(names, colors):\n",
    "    points[name], = ax3d.plot([], [], [], marker='o', linestyle='None', color=color, label=name)\n",
    "\n",
    "ax3d.set_xlabel(\"W[0,0]\")\n",
    "ax3d.set_ylabel(\"W[1,0]\")\n",
    "ax3d.set_zlabel(\"Loss\")\n",
    "ax3d.set_title(\"3D Surface - Optimizer Movement\")\n",
    "ax3d.legend()\n",
    "\n",
    "def update3d(frame):\n",
    "\n",
    "    optimizer_data = [\n",
    "        (\"GD\", traj_gd, hist_gd),\n",
    "        (\"SGD\", traj_sgd, hist_sgd),\n",
    "        (\"MB\", traj_mb, hist_mb),\n",
    "        (\"Nesterov\", traj_nest, hist_nest),\n",
    "        (\"Adagrad\", traj_ada, hist_ada),\n",
    "        (\"RMSProp\", traj_rms, hist_rms),\n",
    "        (\"Adam\", traj_adam, hist_adam)\n",
    "    ]\n",
    "\n",
    "    for name, traj, hist in optimizer_data:\n",
    "        w1, w2 = traj[frame]\n",
    "        loss = hist[frame][1]\n",
    "        points[name].set_data([w1], [w2])\n",
    "        points[name].set_3d_properties([loss])\n",
    "\n",
    "    return list(points.values())\n",
    "\n",
    "ani3d = animation.FuncAnimation(\n",
    "    fig3d,\n",
    "    update3d,\n",
    "    frames=iterations,\n",
    "    interval=80\n",
    ")\n",
    "\n",
    "HTML(ani3d.to_jshtml())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3f89ce-99ca-48b0-841f-d3a6bf6a8b97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
